{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 7, 7, 192)    576         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 7, 7, 192)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 7, 7, 192)    258048      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 3, 3, 320)    552960      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 3, 3, 192)    331776      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 3, 3, 320)    960         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 3, 3, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 3, 3, 320)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_165[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 3, 3, 448)    1344        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 3, 3, 448)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 3, 3, 384)    1548288     activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 3, 3, 384)    1152        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 3, 3, 384)    1152        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 3, 3, 384)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 3, 3, 384)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 3, 3, 320)    960         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 3, 3, 192)    576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 3, 3, 320)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_176[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 3, 3, 192)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_170[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 3, 3, 448)    1344        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 3, 3, 448)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 3, 3, 384)    1548288     activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 3, 3, 384)    1152        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 3, 3, 384)    1152        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 3, 3, 384)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 3, 3, 384)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 3, 3, 320)    960         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 3, 3, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 3, 3, 320)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_181[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 3, 3, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_179[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_187[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path_inception = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    "    weights=None\n",
    ")\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable=False\n",
    "  \n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.97):\n",
    "            print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy']\n",
    "             )\n",
    "#model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"/tmp/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"/tmp/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "#shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = '/tmp/training/horses'\n",
    "train_humans_dir = '/tmp/training/humans'\n",
    "validation_horses_dir = '/tmp/validation/horses'\n",
    "validation_humans_dir = '/tmp/validation/humans'\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True\n",
    "                                  )\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size=10, class_mode='binary', target_size=(150,150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir, batch_size=10, class_mode='binary', target_size=(150,150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zephyros/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 38s 352ms/step - loss: 0.3594 - accuracy: 0.8638 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 34s 344ms/step - loss: 0.0162 - accuracy: 0.9981 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "\n",
      "Reached 97.0% accuracy so cancelling training!\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 3,\n",
    "            callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
